{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPncGA2Rh8DZV17hssfgvhb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### ランダムサーチでXGBoostの最低なパラメータを探す"],"metadata":{"id":"ZF2yS_yLiRrw"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from xgboost import DMatrix, train\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import log_loss\n","import random\n","\n","# TSVファイルを読み込む\n","file_path = '/content/drive/My Drive/signate/train/train_0101.tsv'\n","train_data = pd.read_csv(file_path, low_memory=False, sep='\\t')\n","\n","# 新しい特徴量を作成\n","train_data['C2_I11_interaction'] = train_data['C2'] * train_data['I11']\n","train_data['I5_I12_I6_sum'] = train_data['I5'] + train_data['I12'] + train_data['I6']\n","\n","# 目的変数（ターゲット列）と特徴量を分ける\n","target_column = 'click'\n","X = train_data.drop(columns=[target_column, 'id'])\n","y = train_data[target_column]\n","\n","# Categorical featuresはXGBoostに直接渡せないため、One-hotエンコーディング\n","categorical_features = ['C1', 'C4', 'C6', 'C2_freq_group', 'C3_freq_group', 'C5_freq_group']\n","\n","# 訓練時に使用した特徴量リストを保存\n","X = pd.get_dummies(X, columns=categorical_features)\n","saved_feature_columns = X.columns.tolist()\n","\n","# Stratified K-Fold Cross Validation\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# ハイパーパラメータのランダムサーチ\n","def random_search():\n","    param_grid = {\n","        'max_depth': [8, 10],\n","        'learning_rate': [0.08, 0.1],\n","        'subsample': [0.8, 1.0],\n","        'colsample_bytree': [0.8, 1.0],\n","        'gamma': [0, 1],\n","        'reg_alpha': [0, 1],\n","        'reg_lambda': [1, 10],\n","        'min_child_weight': [1, 5, 10],\n","        'n_estimators': [500]\n","    }\n","\n","    best_logloss = float('inf')\n","    best_params = None\n","\n","    for _ in range(5):  # ランダムに5回試行\n","        params = {\n","            'max_depth': random.choice(param_grid['max_depth']),\n","            'learning_rate': random.choice(param_grid['learning_rate']),\n","            'subsample': random.choice(param_grid['subsample']),\n","            'colsample_bytree': random.choice(param_grid['colsample_bytree']),\n","            'gamma': random.choice(param_grid['gamma']),\n","            'reg_alpha': random.choice(param_grid['reg_alpha']),\n","            'reg_lambda': random.choice(param_grid['reg_lambda']),\n","            'min_child_weight': random.choice(param_grid['min_child_weight']),\n","            'objective': 'binary:logistic',\n","            'eval_metric': 'logloss',\n","            'seed': 42\n","        }\n","\n","        logloss_scores = []\n","\n","        for train_idx, val_idx in skf.split(X, y):\n","            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n","            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n","\n","            # XGBoost DMatrix形式に変換\n","            dtrain = DMatrix(X_train, label=y_train)\n","            dval = DMatrix(X_val, label=y_val)\n","\n","            # 早期終了用の評価セット\n","            evals = [(dtrain, 'train'), (dval, 'eval')]\n","\n","            # モデルのトレーニング\n","            model = train(params, dtrain, num_boost_round=500, evals=evals,\n","                          early_stopping_rounds=50, verbose_eval=50)\n","\n","            # loglossを計算\n","            y_pred_prob = model.predict(dval)\n","            logloss = log_loss(y_val, y_pred_prob)\n","            logloss_scores.append(logloss)\n","\n","        mean_logloss = np.mean(logloss_scores)\n","\n","        if mean_logloss < best_logloss:\n","            best_logloss = mean_logloss\n","            best_params = params\n","\n","    return best_params, best_logloss\n","\n","# ランダムサーチの実行\n","best_params, best_logloss = random_search()\n","\n","# 最適パラメータの確認\n","print(\"Best params:\", best_params)\n","print(\"Best logloss:\", best_logloss)\n","\n"],"metadata":{"id":"rKHzFlpFiVfq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ランダムサーチで探したパラメータを適用しxgboostをトレーニングする"],"metadata":{"id":"3gSlN-djilKY"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from xgboost import DMatrix, train\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import log_loss\n","import pickle\n","\n","# TSVファイルを読み込む\n","file_path = '/content/drive/My Drive/signate/train/train_0101.tsv'\n","train_data = pd.read_csv(file_path, low_memory=False, sep='\\t')\n","\n","# 新しい特徴量を作成\n","train_data['C2_I11_interaction'] = train_data['C2'] * train_data['I11']\n","train_data['I5_I12_I6_sum'] = train_data['I5'] + train_data['I12'] + train_data['I6']\n","\n","# 目的変数（ターゲット列）と特徴量を分ける\n","target_column = 'click'\n","X = train_data.drop(columns=[target_column, 'id'])\n","y = train_data[target_column]\n","\n","# Categorical featuresはXGBoostに直接渡せないため、One-hotエンコーディング\n","categorical_features = ['C1', 'C4', 'C6', 'C2_freq_group', 'C3_freq_group', 'C5_freq_group']\n","\n","X = pd.get_dummies(X, columns=categorical_features)\n","\n","# 特徴量列名を保存\n","saved_feature_columns = X.columns.tolist()\n","with open('/content/drive/My Drive/signate/submission/saved_feature_columns.pkl', 'wb') as f:\n","    pickle.dump(saved_feature_columns, f)\n","\n","# Stratified K-Fold Cross Validation\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# 固定されたベストパラメータ\n","best_params = {\n","    'max_depth': 5,\n","    'learning_rate': 0.08,\n","    'subsample': 1.0,\n","    'colsample_bytree': 1.0,\n","    'gamma': 1,\n","    'reg_alpha': 0,\n","    'reg_lambda': 10,\n","    'min_child_weight': 1,\n","    'objective': 'binary:logistic',\n","    'eval_metric': 'logloss',\n","    'seed': 42\n","}\n","\n","logloss_scores = []\n","\n","for train_idx, val_idx in skf.split(X, y):\n","    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n","    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n","\n","    # XGBoost DMatrix形式に変換\n","    dtrain = DMatrix(X_train, label=y_train)\n","    dval = DMatrix(X_val, label=y_val)\n","\n","    # 早期終了用の評価セット\n","    evals = [(dtrain, 'train'), (dval, 'eval')]\n","\n","    # モデルのトレーニング\n","    model = train(best_params, dtrain, num_boost_round=1000, evals=evals,\n","                  early_stopping_rounds=50, verbose_eval=50)\n","\n","    # loglossを計算\n","    y_pred_prob = model.predict(dval)\n","    logloss = log_loss(y_val, y_pred_prob)\n","    logloss_scores.append(logloss)\n","\n","# クロスバリデーションの平均logloss\n","mean_logloss = np.mean(logloss_scores)\n","print(\"Mean Logloss across folds:\", mean_logloss)\n","\n","# モデルを保存\n","model_file_path = '/content/drive/My Drive/signate/submission/xgboost_model_0103_1.xgb'\n","model.save_model(model_file_path)\n","print(f\"Model saved to: {model_file_path}\")\n"],"metadata":{"id":"HgjTwMIaim0D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Mean Logloss across folds: 0.20845315925409133"],"metadata":{"id":"b9tHt5eNi2rr"}}]}